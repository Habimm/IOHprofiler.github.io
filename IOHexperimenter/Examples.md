---
layout: page
title: Examples
parent: IOHexperimenter
nav_order: 2
permalink: /IOHexperimenter/Examples/
--- 

Examples
==================================

This page introduces two examples of implementing algorithms by C and Python.

## (1+1) Evolutionary algorithm by C
IOHexperimenter provides an example interface in [user_algorithm.c](https://github.com/IOHprofiler/IOHexperimenter/blob/master/code-experiments/build/c/user_algorithm.c), Users can implement their own algorithms by replacing content in the file. There are values of three variables to be modified by users in the file. `BUDGET_MULTIPLIER` is about the maximal budget for each run of experiments, which is equal to `dimension * BUDGET_MULTIPLIER`， and `INDEPENDENT_RESTARTS` is the number of independent runs for each problem. For example,
```c
static const size_t BUDGET_MULTIPLIER = 50;
static const size_t INDEPENDENT_RESTARTS = 1;
static const uint32_t RANDOM_SEED = 1;
``` 
The algorithm implementation must be done in `user_Algorithm()` function, the arguments of the function is
```c
void User_Algorithm(evaluate_function_t evaluate,
                      const size_t dimension,
                      const size_t number_of_objectives,
                      const int *lower_bounds,
                      const int *upper_bounds,
                      const size_t max_budget,
                      IOHprofiler_random_state_t *random_generator)
```
where `evaluation` is a function to evaluate individuals, `random_generator` is a parameter for random generators supplied by the tool, and other arguments are useful information for users. An example of (1+1) evolutionary algorithm is as below.
```c
  int *parent = IOHprofiler_allocate_int_vector(dimension);
  int *offspring = IOHprofiler_allocate_int_vector(dimension);
  int *best = IOHprofiler_allocate_int_vector(dimension);
  double *y = IOHprofiler_allocate_vector(number_of_objectives);

  
  double best_value;
  size_t i, j, l;
  size_t number_of_parameters = 3;
  double *p = IOHprofiler_allocate_vector(number_of_parameters);
  int hit_optimal = 0;
  int lambda = 1;
  double mutation_rate = 1/(double)dimension;
  
  generatingIndividual(parent,dimension,random_generator);
  
  p[0] = lambda; p[1] = 0.0; p[2] = 0.0;
  set_parameters(number_of_parameters,p);
  evaluate(parent,y);
  
  CopyIndividual(parent,best,dimension);
  best_value = y[0];

  for (i = 1; i < max_budget; ) {
    for(j = 0; j < lambda; ++j){
      
      CopyIndividual(parent,offspring,dimension);
      
      l = mutateIndividual(offspring,dimension,mutation_rate,random_generator);
      p[0] = lambda; p[1] = mutation_rate; p[2] = (double)l;
      set_parameters(number_of_parameters,p);
      evaluate(offspring, y);
      
      ++i;
      if(i == max_budget) {
        break;
      }

      if(if_hit_optimal()) {
        hit_optimal = 1;
        break;
      }

      if(y[0] > best_value){
        best_value = y[0];
        CopyIndividual(offspring,best,dimension);
      }
    }

    if(hit_optimal) {
      break;
    }   
    CopyIndividual(best,parent,dimension);
  }

  IOHprofiler_free_memory(parent);
  IOHprofiler_free_memory(offspring);
  IOHprofiler_free_memory(best);
  IOHprofiler_free_memory(p);
  IOHprofiler_free_memory(y);
```
where mutation rate is fixed, and for each generation an offspring is generated by a mutate operator `mutateIndividual` and `l` is the number of flipped bits in mutation. Then offspring are evaluated by `evaluate(offspring,y)`, `y` is a vector stores objectives. Every time that `evaluate` function is invoked, users can call `set_parameters(number_of_parameters,p)` to store some parameters values into log files. Please make sure that `number_of_parameters` is equal to the length of `p`. `if_hit_optimal()` returns true if the optimal of the problem has been found. 

## Random search by Python
IOHexperimenter provides an example interface in [user_algorithm.py](https://github.com/IOHprofiler/IOHexperimenter/blob/master/code-experiments/build/python/user_algorithm.py), Users can implement their own algorithms by replacing content in the file. There are values of three variables to be modified by users in the file. `budget` is about the maximal budget for each run of experiments, which is equal to `dimension * budget`， and `independent_restart` is the number of independent runs for each problem. For example,
```python
independent_restart = 1
budget = 2 
```

The algorithm implementation must be done in `user_algorithm()` function, the arguments of the function is
```python
def user_algorithm(fun,lbounds,ubounds,budget)
```
where `fun` is the class for testing problem, `lbounds` and `ubounds`are arrays for bounds of variables, and `budget` is maximal evaluations. An example of random search is as below.
```python
    lbounds, ubounds = np.array(lbounds), np.array(ubounds)
    dim, best_value = fun.dimension, 0
    while budget > 0:
        X = lbounds + (ubounds - lbounds + 1) * np.random.rand(1, dim)
        X = X.astype(int);
        para = np.array([budget])
        fun.set_parameters(para)
        F = [fun(x) for x in X]
        if fun.number_of_objectives == 1:
            index = np.argmin(F)
            if best_value is None or F[index] > best_value:
                best_value = F[index]
        budget -= 1
    return best_value
```
A random bit string `x` is generated in each generation, and `fun(x)` returns the corresponding fitness value. Before calling `fun(x)`, `fun.set_parameters()` is used to store an array of `para`, which means values of parameters will be logged. 

To know more configurations about the experiments, please visit configurations for [C](https://github.com/IOHprofiler/IOHexperimenter/tree/master/code-experiments/build/c) and [Python](https://github.com/IOHprofiler/IOHexperimenter/tree/master/code-experiments/build/python).

